{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Zadanie 1.\n",
        "Zaimplementuj w środowisku MPI obliczanie równoległe liczby PI z wzoru Leibniz-a.\n",
        "Proces 0, to proces Root, który zarządza obliczeniami:\n",
        "- wysyła do procesów roboczych Slave, indeksy wyrazów szeregu poczatek_local i koniec_local, \n",
        "z których należy obliczyć wyniki cząstkowe\n",
        "- zbiera wyniki cząstkowe z procesów i wyświetla wynik przybliżenia PI"
      ],
      "metadata": {
        "id": "HSnqzMyeIu5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "cat > pi-mpi.c <<EOF\n",
        "#include \n",
        "#include \n",
        "#include \n",
        "\n",
        "// Leibniz \n",
        "\n",
        "double potega(double podstawa , int wykladnik ){\n",
        "  \tdouble wynik=1.0;\n",
        "  for (int i = 1; i <= wykladnik; i++)\n",
        "    {\n",
        "        wynik*=podstawa;\n",
        "    }\n",
        "\n",
        "\n",
        "  return wynik ; \n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "    //tworzenie zmiennych globalnych\n",
        "    int i,np,lp;\n",
        "    int tag=50;\n",
        "    MPI_Status status;\n",
        "    MPI_Init(&argc, &argv);\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &np);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &lp);\n",
        "    \n",
        "    //jesli proces ma numer 0 to:\n",
        "    if(np ==0)\n",
        "    {\n",
        "      //tworzenie zmiennych lokalnych\n",
        "      double pole = 0 ,s=0;\n",
        "      printf(\"\\n Obliczenie liczny pi ze wzoru leibniza\");\n",
        "   \n",
        "      //odbieranie oraz sumowanie wynikow z wszystkich procesow\n",
        "\n",
        "      for(i=1; i<lp; i++)\n",
        "      {\n",
        "        MPI_Recv(&s, 1, MPI_DOUBLE, i, tag, MPI_COMM_WORLD, &status);\n",
        "        pole +=s;\n",
        "      }\n",
        "\n",
        "      //wypisanie wartosci pola\n",
        "      printf(\"\\nwartosc liczby pi ze wzoru Leibnitza = %1f\\n\", 4 *  pole);\n",
        "    }\n",
        "\n",
        "    if(np != 0)\n",
        "    {\n",
        "      //tworzenie zmiennych lokalnych\n",
        "      double s1 = potega( -1 , np - 1   )   / ( 2 *  np - 1  )   ; \n",
        "      printf(\"%f :  \" , s1);\n",
        "      // s1 = 0;\n",
        "      //wysylanie liczby \n",
        "      MPI_Send(&s1, 1, MPI_DOUBLE, 0, tag, MPI_COMM_WORLD);\n",
        "    }\n",
        "    MPI_Finalize();\n",
        "}\n",
        "EOF\n",
        "mpicc pi-mpi.c && mpirun -n 40 --allow-run-as-root a.out"
      ],
      "metadata": {
        "id": "uKiws3jwIynM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Zadanie 2\n",
        "Zaimplementuj w środowisku MPI wyznaczenie numerycznej wartość całki y=f(x) (postać funkcji \n",
        "wybierasz sam) w przedziale <a,b> przy pomocy N trapezów.\n",
        "Proces 0, to proces Root, który zarządza obliczeniami:\n",
        "- wysyła do procesów roboczych Slave początek a_local i koniec b_local lokalnego przedziału \n",
        "całkowania dla danego procesu oraz liczbę N_local trapezów, z których należy policzyć całkę\n",
        "- zbiera wyniki cząstkowe z procesów, i wyświetla wynik całki"
      ],
      "metadata": {
        "id": "Z7cSwUFeInf3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRqImRNO7Vyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "745fcec5-881b-44fc-9eb7-89a62d36b435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Obliczanie calki oznaczonej metoda trapezu dla funkcji f(x)=xPole trapezu wynosi: 1.000000\n",
            "Pole trapezu wynosi: 0.445312\n",
            "Pole trapezu wynosi: 0.585938\n",
            "Pole trapezu wynosi: 0.726562\n",
            "Pole trapezu wynosi: 0.867188\n",
            "Pole trapezu wynosi: 1.007812\n",
            "Pole trapezu wynosi: 1.148438\n",
            "Pole trapezu wynosi: 1.289062\n",
            "\n",
            "Pole pod calka wynosi = 7.070312\n"
          ]
        }
      ],
      "source": [
        "%%sh \n",
        "cat > pi-mpi.c << EOF\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "double funkcja(double x) {\n",
        "return x; \n",
        "}\n",
        "int main(int argc, char *argv[]) {\n",
        "int i,np,lp;\n",
        "int tag=50;\n",
        "MPI_Status status;\n",
        "MPI_Init(&argc, &argv);\n",
        "MPI_Comm_rank(MPI_COMM_WORLD, &np);\n",
        "MPI_Comm_size(MPI_COMM_WORLD, &lp);\n",
        "//jeśli proces ma numer 0 to:\n",
        "if (np == 0) {\n",
        "//Tworzenie zmiennych lokalnych\n",
        "double h,xp,xk,pole,s=0;\n",
        "printf(\"\\nObliczanie calki oznaczonej metoda trapezu dla funkcji f(x)=x\");\n",
        "//Poczatek przedzialu calkowania xp \n",
        "xp = 1.0;\n",
        "//Koniec przedzialu calkowania xk \n",
        "xk = 4.0;\n",
        "// obliczanie wartości h\n",
        "h=(xk-xp)/(double)lp;\n",
        "// wysylanie wartosci ci xp i xk oraz h do poszczegolnych procesow\n",
        "for(i=0;i<lp;i++)\n",
        "{\n",
        "MPI_Send(&xp, 1, MPI_DOUBLE, i,tag, MPI_COMM_WORLD);\n",
        "MPI_Send(&xk, 1, MPI_DOUBLE, i,tag, MPI_COMM_WORLD);\n",
        "MPI_Send(&h, 1, MPI_DOUBLE, i,tag, MPI_COMM_WORLD);\n",
        "}\n",
        "// odbieranie oraz sumowanie wyników z wszystkich procesów \n",
        "for(i=0;i<lp;i++)\n",
        "{\n",
        "MPI_Recv(&s, 1, MPI_DOUBLE, i, tag,MPI_COMM_WORLD, &status);\n",
        "pole+=s;\n",
        "printf(\"Pole trapezu wynosi: %1f\\n\"  , s) ;\n",
        "\n",
        "}\n",
        "// wypisanie wartości pola\n",
        "printf(\"\\nPole pod calka wynosi = %lf\\n\",pole); \n",
        "}\n",
        "else\n",
        "{\n",
        "//tworzenie zmiennych lokalnych\n",
        "double s,h,xp,xk;\n",
        "double np2=np;\n",
        "// odbieranie wartości od procesu 0 \n",
        "MPI_Recv(&xp, 1, MPI_DOUBLE, 0, tag,MPI_COMM_WORLD, &status);\n",
        "MPI_Recv(&xk, 1, MPI_DOUBLE, 0, tag,MPI_COMM_WORLD, &status);\n",
        "MPI_Recv(&h, 1, MPI_DOUBLE, 0, tag,MPI_COMM_WORLD, &status);\n",
        "// obliczanie pola trapezu dla podanej funkcji\n",
        "s=( funkcja(  xp  +  (np - 1 )  * h)  + funkcja(  xp  +  np * h)  ) * 0.5 * h; \n",
        "//wysyłanie pola trapezu do procesu 0\n",
        "MPI_Send(&s, 1, MPI_DOUBLE, 0,tag, MPI_COMM_WORLD); \n",
        "}\n",
        "MPI_Finalize();\n",
        "}\n",
        "EOF\n",
        "mpicc pi-mpi.c && mpirun -n 8 --allow-run-as-root a.out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Zadanie 3\n",
        "Zaimplementuj program mnożenia macierzy A przez wektor B\n",
        "Proces 0, to proces Root, który zarządza obliczeniami:\n",
        "- inicjuje wartości macierzy A i wektora B \n",
        "- wysyła do procesów roboczych Slave fragmenty macierzy A i wektora B \n",
        "- zbiera wyniki cząstkowe z procesów, i wyświetla wynik całki"
      ],
      "metadata": {
        "id": "cwL0dk_qJI56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "cat > pi-mpi.c << EOF\n",
        "#include <stdlib.h> #include <stdio.h> #include <mpi.h> #include <time.h> #include <sys/time.h>\n",
        "/* Przyjmujemy, ze proces 0 to proces Root, który rozdziela wiersze\n",
        "i kolumny macierzy B, C pomiędzy procesy robocze Slave wykonujące \n",
        "obliczenia cząstkowe mnożenia macierzy. Procesy Slave zwracają wyniki \n",
        "do procesu Root, z których składa macierz wynikową A */\n",
        "//Liczba wierszy i kolumn w macierzach A, B, C #define N 40\n",
        "MPI_Status status;\n",
        "double A[N][N],B[N],C[N][N];\n",
        "int main(int argc, char **argv) {\n",
        "int processCount, processId, slaveTaskCount, source, dest, rows, offset;\n",
        "struct timeval start, stop;\n",
        "//Inicjalizacja srodowiska MPI\n",
        "MPI_Init(&argc, &argv);\n",
        "//Uzyskanie numeru aktualnego procesu\n",
        "MPI_Comm_rank(MPI_COMM_WORLD, &processId);\n",
        "//Uzyskanie liczby wszystkich procesów\n",
        "MPI_Comm_size(MPI_COMM_WORLD, &processCount);\n",
        "//Liczba procesów Slave mniejsza o 1 niz processCount\n",
        "slaveTaskCount = processCount - 1;\n",
        "//Przyjęto, ze proces 0 Root (Master) - poniżej jego kod\n",
        "if (processId == 0) {\n",
        "double start = MPI_Wtime();\n",
        "// Inicjalizacja macierzy A i B\n",
        "srand ( time(NULL) );\n",
        "for (int i = 0; i<N; i++) {\n",
        "for (int j = 0; j<N; j++) {\n",
        "A[i][j]= rand()%10;\n",
        "//B[i][j]= rand()%10;\n",
        "}}\n",
        "//Wypisanie zawartości macierzy A i B\n",
        "printf(\"\\n Mnozenie macierzy za pomoca MPI \\n\");\n",
        "printf(\"\\nMacierz A\\n\\n\");\n",
        "for (int i = 0; i<N; i++) {\n",
        "for (int j = 0; j<N; j++) {\n",
        "printf(\"%.0f\\t\", A[i][j]);\n",
        "}\n",
        "printf(\"\\n\");\n",
        "}\n",
        "printf(\"\\nMacierz B\\n\\n\");\n",
        "for (int i = 0; i<N; i++) {\n",
        "for (int j = 0; j<N; j++) {\n",
        "printf(\"%.0f\\t\", B[i][j]);\n",
        "}\n",
        "printf(\"\\n\");\n",
        "}\n",
        "//Okreslene liczby wierzy macierzy A, która zostanie wysłana o każdego\n",
        "//z procesów Slave\n",
        "rows = N/slaveTaskCount;\n",
        "//Zmienna offset określa aktualny pierwszy z wierszy do wysłania do\n",
        "//aktualnego procesu Slave\n",
        "offset = 0;\n",
        "// Przygotowujemy wiersze i kolumny do wysłania do kolejnych procesów\n",
        "//Slave o Id od 1 do slaveTaskCount, zostaną one przesłane wiadomością \n",
        "//z tag 1\n",
        "for (dest=1; dest <= slaveTaskCount; dest++)\n",
        "{\n",
        "//Przesylamy offset wzledem wiersza 0\n",
        "MPI_Send(&offset, 1, MPI_INT, dest, 1, MPI_COMM_WORLD);\n",
        "//Ile wierszy przesylamy\n",
        "MPI_Send(&rows, 1, MPI_INT, dest, 1, MPI_COMM_WORLD);\n",
        "//przesylamy wiersze macierzy A do procesow Slave\n",
        "MPI_Send(&A[offset][0], rows*N, MPI_DOUBLE,dest,1, MPI_COMM_WORLD);\n",
        "//Przesylamy kolumny macierzy B do procesow Slave\n",
        "MPI_Send(&B, N*N, MPI_DOUBLE, dest, 1, MPI_COMM_WORLD);\n",
        "//Modyfikujemy aktualną wartość zmiennej offset\n",
        "offset = offset + rows; }\n",
        "//Proces Root czeka aż procesy Slave obliczą cząstkowe iloczyny wierszy\n",
        "//i kolumn z macierzy A i B, wyniki zostaną odebrane z wiadomościach\n",
        "// z tag 2\n",
        "for (int i = 1; i <= slaveTaskCount; i++)\n",
        "{\n",
        "source = i;\n",
        "//Proces Root otrzymuje offset od aktualnego procesu Slave\n",
        "MPI_Recv(&offset, 1, MPI_INT, source, 2, MPI_COMM_WORLD, &status);\n",
        "//Proces Root otrzymuje liczbę wierszy, którą otrzyma od aktualnego\n",
        "//procesu Slave\n",
        "MPI_Recv(&rows, 1, MPI_INT, source, 2, MPI_COMM_WORLD, &status);\n",
        "//Otrzymanie danych cząstkowych z mnożenia A*B do C\n",
        "MPI_Recv(&C[offset][0], rows*N, MPI_DOUBLE, source, 2 , MPI_COMM_WORLD, &status);\n",
        "}\n",
        "//Wypisanie macierzy wynikowej C\n",
        "printf(\"\\nWynikowa macierz C = A * B:\\n\\n\");\n",
        "for (int i = 0; i<N; i++) {\n",
        "for (int j = 0; j<N; j++)\n",
        "printf(\"%.0f\\t\", C[i][j]);\n",
        "printf (\"\\n\");\n",
        "}\n",
        "printf (\"\\n\");\n",
        "double end = MPI_Wtime();\n",
        "printf(\"Czas obliczen %f\",end - start);\n",
        "} //Koniec kodu procesu Root\n",
        "// Kod do wykonania przez procesy Slave\n",
        "if (processId > 0) {\n",
        "// Podanie procesom Slave numeru procesu Root\n",
        "source = 0;\n",
        "//Procesy Slave czekają na wiadomości z tag 1 od procesu Root\n",
        "//Każdy z procesów Slave wykonuje oddzielnie następujący kod\n",
        "//Procesy Slave otrzymują wartość offsetu od procesu Root\n",
        "MPI_Recv(&offset, 1, MPI_INT, source, 1, MPI_COMM_WORLD, &status);\n",
        "// Procesy Slave otrzymują liczbę wierszy, która zostanie przesłana od\n",
        "// procesu Root\n",
        "MPI_Recv(&rows, 1, MPI_INT, source, 1, MPI_COMM_WORLD, &status);\n",
        "// Procesy Slave otrzymują fragmenty macierzy A od procesu Root\n",
        "MPI_Recv(&A, rows*N, MPI_DOUBLE, source, 1, MPI_COMM_WORLD, &status);\n",
        "// Procesy Slave otrzymują fragmenty macierzy B od procesu Root\n",
        "MPI_Recv(&B, N*N, MPI_DOUBLE, source, 1, MPI_COMM_WORLD, &status);\n",
        "// Mnożenie macierz y\n",
        "for (int k = 0; k<N; k++) {\n",
        "for (int i = 0; i<rows; i++) {\n",
        "//\n",
        "C[i][k] = 0.0;\n",
        "// Element A[i][j] mnożony przez B[j][k]\n",
        "for (int j = 0; j<N; j++)\n",
        "C[i][k] = C[i][k] + A[i][j] * B[j][k];\n",
        "}}\n",
        "// Wyniki cząstkowe są wysyłane z procesów Slave do procesu\n",
        "Root wiadomościami z tag 2\n",
        "//Offset zostanie wysłany do Root\n",
        "MPI_Send(&offset, 1, MPI_INT, 0, 2, MPI_COMM_WORLD);\n",
        "//Liczba wierszy zostanie wysłana do Root\n",
        "MPI_Send(&rows, 1, MPI_INT, 0, 2, MPI_COMM_WORLD);\n",
        "//Wyznaczony fragment macierzy C zostanie wysłany do Root\n",
        "MPI_Send(&C, rows*N, MPI_DOUBLE, 0, 2, MPI_COMM_WORLD);\n",
        "}\n",
        "MPI_Finalize();\n",
        "}\n",
        "EOF\n",
        "mpicc pi-mpi.c && mpirun -n 4 --allow-run-as-root a.out"
      ],
      "metadata": {
        "id": "5Tx0m-ofElCf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}