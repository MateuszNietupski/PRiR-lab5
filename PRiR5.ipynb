{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Zadanie 1.\n",
        "Zaimplementuj w środowisku MPI obliczanie równoległe liczby PI z wzoru Leibniz-a.\n",
        "Proces 0, to proces Root, który zarządza obliczeniami:\n",
        "- wysyła do procesów roboczych Slave, indeksy wyrazów szeregu poczatek_local i koniec_local, \n",
        "z których należy obliczyć wyniki cząstkowe\n",
        "- zbiera wyniki cząstkowe z procesów i wyświetla wynik przybliżenia PI"
      ],
      "metadata": {
        "id": "HSnqzMyeIu5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "cat > pi-mpi.c <<EOF\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <mpi.h>\n",
        "#include <time.h>\n",
        "#include <sys/time.h>\n",
        "\n",
        "// Leibniz \n",
        "\n",
        "double potega(double podstawa , int wykladnik ){\n",
        "  \tdouble wynik=1.0;\n",
        "  for (int i = 1; i <= wykladnik; i++)\n",
        "    {\n",
        "        wynik*=podstawa;\n",
        "    }\n",
        "\n",
        "\n",
        "  return wynik ; \n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[])\n",
        "{\n",
        "    //tworzenie zmiennych globalnych\n",
        "    int i,np,lp;\n",
        "    int tag=50;\n",
        "    MPI_Status status;\n",
        "    MPI_Init(&argc, &argv);\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &np);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &lp);\n",
        "    \n",
        "    //jesli proces ma numer 0 to:\n",
        "    if(np ==0)\n",
        "    {\n",
        "      //tworzenie zmiennych lokalnych\n",
        "      double pole = 0 ,s=0;\n",
        "      printf(\"\\n Obliczenie liczny pi ze wzoru leibniza\");\n",
        "   \n",
        "      //odbieranie oraz sumowanie wynikow z wszystkich procesow\n",
        "\n",
        "      for(i=1; i<lp; i++)\n",
        "      {\n",
        "        MPI_Recv(&s, 1, MPI_DOUBLE, i, tag, MPI_COMM_WORLD, &status);\n",
        "        pole +=s;\n",
        "      }\n",
        "\n",
        "      //wypisanie wartosci pola\n",
        "      printf(\"\\nwartosc liczby pi ze wzoru Leibnitza = %1f\\n\", 4 *  pole);\n",
        "    }\n",
        "\n",
        "    if(np != 0)\n",
        "    {\n",
        "      //tworzenie zmiennych lokalnych\n",
        "      double s1 = potega( -1 , np - 1   )   / ( 2 *  np - 1  )   ; \n",
        "      printf(\"%f :  \" , s1);\n",
        "      // s1 = 0;\n",
        "      //wysylanie liczby \n",
        "      MPI_Send(&s1, 1, MPI_DOUBLE, 0, tag, MPI_COMM_WORLD);\n",
        "    }\n",
        "    MPI_Finalize();\n",
        "}\n",
        "EOF\n",
        "mpicc pi-mpi.c && mpirun -n 40 --allow-run-as-root a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKiws3jwIynM",
        "outputId": "c9feaecf-d495-41cb-b05c-38288b25d5e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Obliczenie liczny pi ze wzoru leibniza\n",
            "wartosc liczby pi ze wzoru Leibnitza = 3.167229\n",
            "-0.018182 :  0.012987 :  -0.090909 :  -0.014085 :  0.034483 :  -0.052632 :  0.200000 :  -0.025641 :  -0.016949 :  -0.019608 :  0.047619 :  -0.023256 :  -0.015873 :  0.076923 :  0.040000 :  0.013699 :  -0.333333 :  0.111111 :  -0.043478 :  -0.032258 :  0.030303 :  0.024390 :  0.022222 :  -0.021277 :  0.018868 :  0.016393 :  -0.014925 :  -0.013333 :  -0.142857 :  0.027027 :  0.017544 :  0.015385 :  1.000000 :  -0.066667 :  0.014493 :  0.058824 :  -0.037037 :  -0.028571 :  0.020408 :  "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Zadanie 2\n",
        "Zaimplementuj w środowisku MPI wyznaczenie numerycznej wartość całki y=f(x) (postać funkcji \n",
        "wybierasz sam) w przedziale <a,b> przy pomocy N trapezów.\n",
        "Proces 0, to proces Root, który zarządza obliczeniami:\n",
        "- wysyła do procesów roboczych Slave początek a_local i koniec b_local lokalnego przedziału \n",
        "całkowania dla danego procesu oraz liczbę N_local trapezów, z których należy policzyć całkę\n",
        "- zbiera wyniki cząstkowe z procesów, i wyświetla wynik całki"
      ],
      "metadata": {
        "id": "Z7cSwUFeInf3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yRqImRNO7Vyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "745fcec5-881b-44fc-9eb7-89a62d36b435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Obliczanie calki oznaczonej metoda trapezu dla funkcji f(x)=xPole trapezu wynosi: 1.000000\n",
            "Pole trapezu wynosi: 0.445312\n",
            "Pole trapezu wynosi: 0.585938\n",
            "Pole trapezu wynosi: 0.726562\n",
            "Pole trapezu wynosi: 0.867188\n",
            "Pole trapezu wynosi: 1.007812\n",
            "Pole trapezu wynosi: 1.148438\n",
            "Pole trapezu wynosi: 1.289062\n",
            "\n",
            "Pole pod calka wynosi = 7.070312\n"
          ]
        }
      ],
      "source": [
        "%%sh \n",
        "cat > pi-mpi.c << EOF\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "double funkcja(double x) {\n",
        "return x; \n",
        "}\n",
        "int main(int argc, char *argv[]) {\n",
        "int i,np,lp;\n",
        "int tag=50;\n",
        "MPI_Status status;\n",
        "MPI_Init(&argc, &argv);\n",
        "MPI_Comm_rank(MPI_COMM_WORLD, &np);\n",
        "MPI_Comm_size(MPI_COMM_WORLD, &lp);\n",
        "//jeśli proces ma numer 0 to:\n",
        "if (np == 0) {\n",
        "//Tworzenie zmiennych lokalnych\n",
        "double h,xp,xk,pole,s=0;\n",
        "printf(\"\\nObliczanie calki oznaczonej metoda trapezu dla funkcji f(x)=x\");\n",
        "//Poczatek przedzialu calkowania xp \n",
        "xp = 1.0;\n",
        "//Koniec przedzialu calkowania xk \n",
        "xk = 4.0;\n",
        "// obliczanie wartości h\n",
        "h=(xk-xp)/(double)lp;\n",
        "// wysylanie wartosci ci xp i xk oraz h do poszczegolnych procesow\n",
        "for(i=0;i<lp;i++)\n",
        "{\n",
        "MPI_Send(&xp, 1, MPI_DOUBLE, i,tag, MPI_COMM_WORLD);\n",
        "MPI_Send(&xk, 1, MPI_DOUBLE, i,tag, MPI_COMM_WORLD);\n",
        "MPI_Send(&h, 1, MPI_DOUBLE, i,tag, MPI_COMM_WORLD);\n",
        "}\n",
        "// odbieranie oraz sumowanie wyników z wszystkich procesów \n",
        "for(i=0;i<lp;i++)\n",
        "{\n",
        "MPI_Recv(&s, 1, MPI_DOUBLE, i, tag,MPI_COMM_WORLD, &status);\n",
        "pole+=s;\n",
        "printf(\"Pole trapezu wynosi: %1f\\n\"  , s) ;\n",
        "\n",
        "}\n",
        "// wypisanie wartości pola\n",
        "printf(\"\\nPole pod calka wynosi = %lf\\n\",pole); \n",
        "}\n",
        "else\n",
        "{\n",
        "//tworzenie zmiennych lokalnych\n",
        "double s,h,xp,xk;\n",
        "double np2=np;\n",
        "// odbieranie wartości od procesu 0 \n",
        "MPI_Recv(&xp, 1, MPI_DOUBLE, 0, tag,MPI_COMM_WORLD, &status);\n",
        "MPI_Recv(&xk, 1, MPI_DOUBLE, 0, tag,MPI_COMM_WORLD, &status);\n",
        "MPI_Recv(&h, 1, MPI_DOUBLE, 0, tag,MPI_COMM_WORLD, &status);\n",
        "// obliczanie pola trapezu dla podanej funkcji\n",
        "s=( funkcja(  xp  +  (np - 1 )  * h)  + funkcja(  xp  +  np * h)  ) * 0.5 * h; \n",
        "//wysyłanie pola trapezu do procesu 0\n",
        "MPI_Send(&s, 1, MPI_DOUBLE, 0,tag, MPI_COMM_WORLD); \n",
        "}\n",
        "MPI_Finalize();\n",
        "}\n",
        "EOF\n",
        "mpicc pi-mpi.c && mpirun -n 8 --allow-run-as-root a.out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Zadanie 3\n",
        "Zaimplementuj program mnożenia macierzy A przez wektor B\n",
        "Proces 0, to proces Root, który zarządza obliczeniami:\n",
        "- inicjuje wartości macierzy A i wektora B \n",
        "- wysyła do procesów roboczych Slave fragmenty macierzy A i wektora B \n",
        "- zbiera wyniki cząstkowe z procesów, i wyświetla wynik całki"
      ],
      "metadata": {
        "id": "cwL0dk_qJI56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sh\n",
        "cat > pi-mpi.c << EOF\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <mpi.h>\n",
        "#include <time.h>\n",
        "#include <sys/time.h>\n",
        "/* Przyjmujemy, ze proces 0 to proces Root, który rozdziela wiersze\n",
        "i kolumny macierzy B, C pomiędzy procesy robocze Slave wykonujące \n",
        "obliczenia cząstkowe mnożenia macierzy. Procesy Slave zwracają wyniki \n",
        "do procesu Root, z których składa macierz wynikową A */\n",
        "//Liczba wierszy i kolumn w macierzach A, B, C #define N 40\n",
        "MPI_Status status;\n",
        "int = 4\n",
        "double A[N][N],B[N],C[N][N];\n",
        "int main(int argc, char **argv) {\n",
        "int processCount, processId, slaveTaskCount, source, dest, rows, offset;\n",
        "struct timeval start, stop;\n",
        "//Inicjalizacja srodowiska MPI\n",
        "MPI_Init(&argc, &argv);\n",
        "//Uzyskanie numeru aktualnego procesu\n",
        "MPI_Comm_rank(MPI_COMM_WORLD, &processId);\n",
        "//Uzyskanie liczby wszystkich procesów\n",
        "MPI_Comm_size(MPI_COMM_WORLD, &processCount);\n",
        "//Liczba procesów Slave mniejsza o 1 niz processCount\n",
        "slaveTaskCount = processCount - 1;\n",
        "//Przyjęto, ze proces 0 Root (Master) - poniżej jego kod\n",
        "if (processId == 0) {\n",
        "double start = MPI_Wtime();\n",
        "// Inicjalizacja macierzy A i B\n",
        "srand ( time(NULL) );\n",
        "for (int i = 0; i<N; i++) {\n",
        "for (int j = 0; j<N; j++) {\n",
        "A[i][j]= rand()%10;\n",
        "//B[i][j]= rand()%10;\n",
        "}}\n",
        "//Wypisanie zawartości macierzy A i B\n",
        "printf(\"\\n Mnozenie macierzy za pomoca MPI \\n\");\n",
        "printf(\"\\nMacierz A\\n\\n\");\n",
        "for (int i = 0; i<N; i++) {\n",
        "for (int j = 0; j<N; j++) {\n",
        "printf(\"%.0f\\t\", A[i][j]);\n",
        "}\n",
        "printf(\"\\n\");\n",
        "}\n",
        "printf(\"\\nMacierz B\\n\\n\");\n",
        "for (int i = 0; i<N; i++) {\n",
        "for (int j = 0; j<N; j++) {\n",
        "printf(\"%.0f\\t\", B[i][j]);\n",
        "}\n",
        "printf(\"\\n\");\n",
        "}\n",
        "//Okreslene liczby wierzy macierzy A, która zostanie wysłana o każdego\n",
        "//z procesów Slave\n",
        "rows = N/slaveTaskCount;\n",
        "//Zmienna offset określa aktualny pierwszy z wierszy do wysłania do\n",
        "//aktualnego procesu Slave\n",
        "offset = 0;\n",
        "// Przygotowujemy wiersze i kolumny do wysłania do kolejnych procesów\n",
        "//Slave o Id od 1 do slaveTaskCount, zostaną one przesłane wiadomością \n",
        "//z tag 1\n",
        "for (dest=1; dest <= slaveTaskCount; dest++)\n",
        "{\n",
        "//Przesylamy offset wzledem wiersza 0\n",
        "MPI_Send(&offset, 1, MPI_INT, dest, 1, MPI_COMM_WORLD);\n",
        "//Ile wierszy przesylamy\n",
        "MPI_Send(&rows, 1, MPI_INT, dest, 1, MPI_COMM_WORLD);\n",
        "//przesylamy wiersze macierzy A do procesow Slave\n",
        "MPI_Send(&A[offset][0], rows*N, MPI_DOUBLE,dest,1, MPI_COMM_WORLD);\n",
        "//Przesylamy kolumny macierzy B do procesow Slave\n",
        "MPI_Send(&B, N*N, MPI_DOUBLE, dest, 1, MPI_COMM_WORLD);\n",
        "//Modyfikujemy aktualną wartość zmiennej offset\n",
        "offset = offset + rows; }\n",
        "//Proces Root czeka aż procesy Slave obliczą cząstkowe iloczyny wierszy\n",
        "//i kolumn z macierzy A i B, wyniki zostaną odebrane z wiadomościach\n",
        "// z tag 2\n",
        "for (int i = 1; i <= slaveTaskCount; i++)\n",
        "{\n",
        "source = i;\n",
        "//Proces Root otrzymuje offset od aktualnego procesu Slave\n",
        "MPI_Recv(&offset, 1, MPI_INT, source, 2, MPI_COMM_WORLD, &status);\n",
        "//Proces Root otrzymuje liczbę wierszy, którą otrzyma od aktualnego\n",
        "//procesu Slave\n",
        "MPI_Recv(&rows, 1, MPI_INT, source, 2, MPI_COMM_WORLD, &status);\n",
        "//Otrzymanie danych cząstkowych z mnożenia A*B do C\n",
        "MPI_Recv(&C[offset][0], rows*N, MPI_DOUBLE, source, 2 , MPI_COMM_WORLD, &status);\n",
        "}\n",
        "//Wypisanie macierzy wynikowej C\n",
        "printf(\"\\nWynikowa macierz C = A * B:\\n\\n\");\n",
        "for (int i = 0; i<N; i++) {\n",
        "for (int j = 0; j<N; j++)\n",
        "printf(\"%.0f\\t\", C[i][j]);\n",
        "printf (\"\\n\");\n",
        "}\n",
        "printf (\"\\n\");\n",
        "double end = MPI_Wtime();\n",
        "printf(\"Czas obliczen %f\",end - start);\n",
        "} //Koniec kodu procesu Root\n",
        "// Kod do wykonania przez procesy Slave\n",
        "if (processId > 0) {\n",
        "// Podanie procesom Slave numeru procesu Root\n",
        "source = 0;\n",
        "//Procesy Slave czekają na wiadomości z tag 1 od procesu Root\n",
        "//Każdy z procesów Slave wykonuje oddzielnie następujący kod\n",
        "//Procesy Slave otrzymują wartość offsetu od procesu Root\n",
        "MPI_Recv(&offset, 1, MPI_INT, source, 1, MPI_COMM_WORLD, &status);\n",
        "// Procesy Slave otrzymują liczbę wierszy, która zostanie przesłana od\n",
        "// procesu Root\n",
        "MPI_Recv(&rows, 1, MPI_INT, source, 1, MPI_COMM_WORLD, &status);\n",
        "// Procesy Slave otrzymują fragmenty macierzy A od procesu Root\n",
        "MPI_Recv(&A, rows*N, MPI_DOUBLE, source, 1, MPI_COMM_WORLD, &status);\n",
        "// Procesy Slave otrzymują fragmenty macierzy B od procesu Root\n",
        "MPI_Recv(&B, N*N, MPI_DOUBLE, source, 1, MPI_COMM_WORLD, &status);\n",
        "// Mnożenie macierz y\n",
        "for (int k = 0; k<N; k++) {\n",
        "for (int i = 0; i<rows; i++) {\n",
        "//\n",
        "C[i][k] = 0.0;\n",
        "// Element A[i][j] mnożony przez B[j][k]\n",
        "for (int j = 0; j<N; j++)\n",
        "C[i][k] = C[i][k] + A[i][j] * B[j][k];\n",
        "}}\n",
        "// Wyniki cząstkowe są wysyłane z procesów Slave do procesu\n",
        "Root wiadomościami z tag 2\n",
        "//Offset zostanie wysłany do Root\n",
        "MPI_Send(&offset, 1, MPI_INT, 0, 2, MPI_COMM_WORLD);\n",
        "//Liczba wierszy zostanie wysłana do Root\n",
        "MPI_Send(&rows, 1, MPI_INT, 0, 2, MPI_COMM_WORLD);\n",
        "//Wyznaczony fragment macierzy C zostanie wysłany do Root\n",
        "MPI_Send(&C, rows*N, MPI_DOUBLE, 0, 2, MPI_COMM_WORLD);\n",
        "}\n",
        "MPI_Finalize();\n",
        "}\n",
        "EOF\n",
        "mpicc pi-mpi.c && mpirun -n 4 --allow-run-as-root a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5Tx0m-ofElCf",
        "outputId": "fee6f087-680f-4238-f485-0a4dfd82b10c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pi-mpi.c:12:5: error: expected identifier or ‘(’ before ‘=’ token\n",
            " int = 4\n",
            "     ^\n",
            "pi-mpi.c: In function ‘main’:\n",
            "pi-mpi.c:30:19: error: ‘N’ undeclared (first use in this function)\n",
            " for (int i = 0; i<N; i++) {\n",
            "                   ^\n",
            "pi-mpi.c:30:19: note: each undeclared identifier is reported only once for each function it appears in\n",
            "pi-mpi.c:32:1: error: ‘A’ undeclared (first use in this function)\n",
            " A[i][j]= rand()%10;\n",
            " ^\n",
            "pi-mpi.c:47:18: error: ‘B’ undeclared (first use in this function)\n",
            " printf(\"%.0f\\t\", B[i][j]);\n",
            "                  ^\n",
            "pi-mpi.c:84:11: error: ‘C’ undeclared (first use in this function)\n",
            " MPI_Recv(&C[offset][0], rows*N, MPI_DOUBLE, source, 2 , MPI_COMM_WORLD, &status);\n",
            "           ^\n",
            "pi-mpi.c:122:1: error: unknown type name ‘Root’\n",
            " Root wiadomościami z tag 2\n",
            " ^~~~\n",
            "pi-mpi.c:122:13: error: stray ‘\\305’ in program\n",
            " Root wiadomościami z tag 2\n",
            "             ^\n",
            "pi-mpi.c:122:14: error: stray ‘\\233’ in program\n",
            " Root wiadomościami z tag 2\n",
            "              ^\n",
            "pi-mpi.c:122:15: error: expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘__attribute__’ before ‘ciami’\n",
            " Root wiadomościami z tag 2\n",
            "               ^~~~~\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-60ca5ca94d2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cat > pi-mpi.c << EOF\\n#include <stdlib.h>\\n#include <stdio.h>\\n#include <mpi.h>\\n#include <time.h>\\n#include <sys/time.h>\\n/* Przyjmujemy, ze proces 0 to proces Root, który rozdziela wiersze\\ni kolumny macierzy B, C pomiędzy procesy robocze Slave wykonujące \\nobliczenia cząstkowe mnożenia macierzy. Procesy Slave zwracają wyniki \\ndo procesu Root, z których składa macierz wynikową A */\\n//Liczba wierszy i kolumn w macierzach A, B, C #define N 40\\nMPI_Status status;\\nint = 4\\ndouble A[N][N],B[N],C[N][N];\\nint main(int argc, char **argv) {\\nint processCount, processId, slaveTaskCount, source, dest, rows, offset;\\nstruct timeval start, stop;\\n//Inicjalizacja srodowiska MPI\\nMPI_Init(&argc, &argv);\\n//Uzyskanie numeru aktualnego procesu\\nMPI_Comm_rank(MPI_COMM_WORLD, &processId);\\n//Uzyskanie liczby wszystkich procesów\\nMPI_Comm_size(MPI_COMM_WORLD, &processCount);\\n//Liczba procesów Slave mniejsza o 1 niz processCount\\nslaveTaskCount = processCount - 1;\\n//Przyjęto, ze proces 0 Root (Master) - poniżej jego kod\\nif (processId == 0) {\\ndouble start = MPI_Wtime();\\n// Inicjalizacja macierzy A i B\\nsrand ( time(NULL) );\\nfor (int i = 0; i<N; i++) {\\nfor (int j = 0; j<N; j++) {\\nA[i][j]= rand()%10;\\n//B[i][j]= rand()%10;\\n}}\\n//Wypisanie zawartości macierzy A i B\\nprintf(\"\\\\n Mnozenie macierzy za pomoca MPI \\\\n...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'cat > pi-mpi.c << EOF\\n#include <stdlib.h>\\n#include <stdio.h>\\n#include <mpi.h>\\n#include <time.h>\\n#include <sys/time.h>\\n/* Przyjmujemy, ze proces 0 to proces Root, kt\\xc3\\xb3ry rozdziela wiersze\\ni kolumny macierzy B, C pomi\\xc4\\x99dzy procesy robocze Slave wykonuj\\xc4\\x85ce \\nobliczenia cz\\xc4\\x85stkowe mno\\xc5\\xbcenia macierzy. Procesy Slave zwracaj\\xc4\\x85 wyniki \\ndo procesu Root, z kt\\xc3\\xb3rych sk\\xc5\\x82ada macierz wynikow\\xc4\\x85 A */\\n//Liczba wierszy i kolumn w macierzach A, B, C #define N 40\\nMPI_Status status;\\nint = 4\\ndouble A[N][N],B[N],C[N][N];\\nint main(int argc, char **argv) {\\nint processCount, processId, slaveTaskCount, source, dest, rows, offset;\\nstruct timeval start, stop;\\n//Inicjalizacja srodowiska MPI\\nMPI_Init(&argc, &argv);\\n//Uzyskanie numeru aktualnego procesu\\nMPI_Comm_rank(MPI_COMM_WORLD, &processId);\\n//Uzyskanie liczby wszystkich proces\\xc3\\xb3w\\nMPI_Comm_size(MPI_COMM_WORLD, &processCount);\\n//Liczba proces\\xc3\\xb3w Slave mniejsza o 1 niz processCount\\nslaveTaskCount = processCount - 1;\\n//Przyj\\xc4\\x99to, ze proces 0 Root (Master) - poni\\xc5\\xbcej jego kod\\nif (processId == 0) {\\ndouble start = MPI_Wtime();\\n// Inicjalizacja macierzy A i B\\nsrand ( time(NULL) );\\nfor (int i = 0; i<N; i++) {\\nfor (int j = 0; j<N; j++) {\\nA[i][j]= rand()%10;\\n//B[i][j]= rand()%10;\\n}}\\n//Wypisanie zawarto\\xc5\\x9bci macierzy A i B\\nprintf(\"\\\\n Mnozenie macierzy za pomoca MPI \\\\n\");\\nprintf(\"\\\\nMacierz A\\\\n\\\\n\")..."
          ]
        }
      ]
    }
  ]
}